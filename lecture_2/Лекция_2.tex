\documentclass{article}
\usepackage[T1,T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}

\usepackage[left=3cm,right=3cm,
    top=3cm,bottom=3cm,bindingoffset=0cm]{geometry}

\usepackage{graphicx}
\usepackage{color}
\usepackage{hyperref}
\usepackage{amsmath}

\usepackage{setspace}
\usepackage{indentfirst}
\usepackage{textcomp}
\usepackage{ifthen}
\usepackage{calc}

\title{Теория Вероятностей и Математическая Статистика\\
ФИИТ, 2 курс, 4 семестр}
\author{Лекция 2}

\begin{document}
\maketitle

В прошлом лекции мы рассмотрели классическую схему теории вероятностей, и даже смогли продолжить теорию на геометрические задачи, отказавшись от условия конечности элементарных исходов. Вспомним основные моменты более подробно.

\section{Алгебра событий}

Допустим, у нас есть множество исходов опыта $\Omega$. На этом множестве мы построим новый объект -- алгебру событий $\mathcal{A}$:

$$ \mathcal{A} = \{A_1, A_2, A_3, \ldots\} $$

И элемент этого множества $a_i \in \mathcal{A}$ -- это набор каких-то элементов, взятых из множества исходов опыта (то есть подмножество $\Omega$):

$$ A_i \in \mathcal{A} = \{ \omega_{i_1}, \omega_{i_2}, \ldots, \omega_{i_n}\} $$

Эта алгебра отвечает некоторым условиям:

\begin{enumerate}
\item $\Omega \in \mathcal{A}$

\item $ A_i, A_j \in \mathcal {A} \Leftrightarrow A_i \cup A_j \in \mathcal{A}$

\item $ A_i \in \mathcal{A} \Leftrightarrow \overline{A_i} \in \mathcal{A} $
\end{enumerate}

Данные условия уже образуют алгебру множеств (или алгебру событий), с таким объектом в математике мы должны были встечаться. Однако, расширим это понятие и модифицируем условие 2 и откажемся от конечности:

\quad

$2^*$. $ A_1, A_2, \ldots, A_n, \ldots \in \mathcal{A} \Leftrightarrow \cup\limits_{i = 1}^{\infty} A_i \in \mathcal{A}$

\quad

Записывая приведенные формулы словами, имеем следующие условия:

\begin{enumerate}
\item Само множество исходов опыта является элементом алгебры
\item Некоторый набор элементов (конечный или бесконечный) является элементом алгебры, когда их объединение так же является элементом алгебры.
\item Элемент входит в алгебру, если его дополнение тоже входит в алгебру.
\end{enumerate}

Таким образом, класс множеств $\mathcal{A}$ замкнут относительно операций 1, 2 и 3 -- получаем алгебру событий. (Предполагает объединение только конечного числа множеств!)

Второй вариант: класс множеств замкнут относительно условия 1, 2*, 3 -- счетно-аддитивная алгебра событий (иначе называется $\sigma$(сигма)-алгебра событий, то есть $\sigma$ заменяет "счетно-аддитивность").

При таком построении класса множеств появляется возможность сопоставить нашим событиям в соответствие число, или, говоря математическим языком, ввести \textbf{меру}. То есть мы можем измерить каждое множество относительно всего множества исходов.

\section{Вероятность случайного события}

\textbf{Определение}. Вероятность случайного события -- это функция $P$, которая отображает \newline ($\sigma$-)алгебру событий $\mathcal{A}$ на числовой отрехок $[0; 1]$:

$$ P : \mathcal{A} \rightarrow [0; 1],$$

и при этом удовлетворяет условиям:

\begin{enumerate}
\item $ P(A) \geq 0 $ \qquad\qquad (неотрицательность)

\item $ P(\Omega) = 1$ \qquad\qquad (нормированность)

\item $ P(A + B) = P(A) + P(B), \forall A, B: A \cdot B = \emptyset $ \qquad\qquad (аддитивность)

\item Пусть $ A_1, A_2, \ldots $ -- монотонная бесконечно убывающая последовательность случайных событий: $ A_1 \supset A_2 \supset A_3 \supset \ldots \supset \ldots$, при этом
 $\cap\limits_{i = 1}^{\infty} A_i = \emptyset \quad \Rightarrow \quad
 \lim\limits_{n\rightarrow\infty}{P(A)} = 0$ \quad (непрерывность)

\end{enumerate}

Записывая словами, \textbf{вероятность} -- это мера непрерывная, нормированная, неотрицательная, аддитивная.

\quad

\textbf{Кстати}, на проятяжении многих столетий не удавалось четко сформулировать аксиоматически основы вероятности, и впервые это сделал академик Колмогоров в 30-е годы 20 века. Ему удалось в терминах теории множеств сформулировать аксиоматику теории вероятностей.

\section{Вероятностное пространство}

\textbf{Определение.} Вероятностное пространство представляет собой тройку, состоящую из:

\begin{enumerate}
\item множества исходов опыта $\Omega$,

\item $\sigma$-алгебры $\mathcal{A}$, построенной на $\Omega$,

\item меры $P$, заданная на $\mathcal{A}$ (и удовлетворяющая аксиомам).
\end{enumerate}

Кратко вероятностное пространство так и обозначают: $\{\Omega, \Mathcal{A}, P\}$.

И, исходя из этого определения, сами случайные события принято обозначать геометрическим фигурами, имеющими площади, на плоскости.

\section{Случайные события}

(Далее шли рисунки с кругами Эйлера, если нужно -- гугол в помощь.)

\begin{enumerate}
\item $A \cup B = A + B$\\
      соответствуют действию "ИЛИ"  (происходит событие $А$ или событие $B$)

\item $A \cap B = AB$\\
      соответствует действию  "И"  (происходит одновременно и событие $А$, и событие $B$)

\item $\overline{A} = \Omega \backslash A$\\
      соответствует "НЕ"(событие $A$ не происходит)

\item $(A \backslash B) \cup (B \backslash A) = A \Delta B =  A\overline{B} + \overline{A}B$\\
      симметрическая разность, соответствует "ЛИБО, ЛИБО" (происходит либо событие $A$, либо событие $B$ , но только не одновременно)

\item Законы Де Моргана так же работают:

\quad $\overline{A + B} = \overline{A} \cdot \overline{B}$

\quad $\overline{A \cdot B} = \overline{A} + \overline{B}$

\item Законы Де Моргана для счетного множества слагаемых или сомножителей:

\quad $ \overline{\sum\limits_{i = 1}^n A_i} = \prod\limits_{i =1}^n \overline{A_i}$

\quad $\overline{\prod\limits_{i = 1}^n A_i} = \sum\limits_{i = 1}^n \overline{A_i}$

\end{enumerate}

\section{Условная вероятность}

На нашем вероятностном пространстве рассматриваются два событий: $A$ и $B$. Мы хотим определить вероятность следующего ытда: $P(A | B)$ -- вероятность события $A$, \textbf{при условии}, что событие $B$ в опыте реализовалось (произошло).

Если событие произошло, значит имеются элементарные ичходы, реализующие $B$, а значит дальше есть два варианта:

\begin{enumerate}
\item событие $A$ не реализовалось -- произошедший элементарный исход для $B$ не реализует $A$

\item событие $A$ реализовалось -- элементарный исход для $B$ содержится в $A$, то есть $A \cap B \not= \emptyset$

\end{enumerate}

То есть:

$$ P(A | B) = \frac{m(A \cap B)}{m(B)} = \frac{m(AB)}{m(B)} ,$$

где $m(\cdot)$ -- мера. Если эту запись домножить на единицу, а единицу построим как отношение меры всего множества к мере всего множества, получим:

$$ \frac{m(AB)}{m(B)}\cdot \frac{m(\Omega)}{m(\Omega)} = \frac{m(AB)}{m(\Omega)} \cdot \frac{m(\Omega)}{m(B)} = \frac{P(AB)}{P(B)}$$

И мы добились записи через вероятности в "безусловном" варианте (буквально, без условий), их мы назовем \textbf{"априорные"} -- вероятности до реализации события $B$, то есть условия (в целом вероятности до основного опыта). Вероятность изначальная (с условием) -- \textbf{"апостериорная"}. Таким образом, получаем формулу, связывающая априорные вероятности с апостериорными:

$$ P(A | B) = \frac{P(AB)}{P(B)} \qquad(1)$$ 

\section{Формула умножения}

Выразим в полученном равенстве (1) числитель. Тогда получим:

$$ P(AB) = P(B) \cdot P(A | B) \qquad (2)$$

Запись (2) называется \textbf{теоремой (формулой) умножения}, которую можно распространить на большее число сомножителей:

$$P(A_1A_2 \ldots A_n) = P(A_1) \cdot P(A_2|A_1) \cdot P(A_3|A_1A_2) \cdot P(A_4|A_1A_2A_3) \ldots P(A_n|A_1 \ldots A_n) $$

\subsection{Пример}

Бросают игральную кость. Нужно найти вероятность того, что выпала тройка, если известно, что выпала нечетное число очков.

\quad

Все множество исходов опыта мы можем написать числами: $\Omega = \{1,2,3,4,5,6\}$.

Событие $A = \{$ выпала тройка $\} = \{3\}$.

Событие $B = \{$ выпало нечетное $\} = \{1, 3, 5\}$

\quad

На что нужно обратить внимание в данном примере? В данном случае ключевыми словами является \textbf{"если известно"} ("при условии") -- такая запись явно говорит, что требуемая вероятность является условной: $P(A|B)$.

В соответствии с общей формулой:

$$P(A|B) = \frac{P(AB)}{P(B)}$$

В нашей конкретной ситуации $P(AB) = P(A)$, а $P(B)$ найти легко. Таким образом:

$$P(A|B) = \frac{P(AB)}{P(B)} = \frac{P(A)}{P(B)} = \frac{1 / 6}{3 / 6} = \frac{1}{3}$$ 

\subsection{Пример}

10-и томное издание наугад расставленно на полке. Найти вероятность 3-й том окажется на 7-м месте; 7-й том -- на 3-м месте, а 5-й том -- на своем месте.

\quad

Сформулируем следующие события:

$A_{37} = \{$ 3-й том на 7-м месте $\}$

$A_{73} = \{$ 7-й том на 3-м месте $\}$

$A_{55} = \{$ 5-й том на 5-м месте $\}$

\quad

Тогда в соответствии с условием, нас интересует вероятность того, что все три события произойдут одновременно. Для этого воспользуемся теоремой умножения:

$$ P(A_{37} \cdot A_{73} \cdot A_{55}) = P(A_{37}) \cdot P(A_{73} | A_{37}) \cdot P(A_{55} | A_{37}\cdot A_{73}) $$

Посчитаем каждые слагаемые:

$P(A_{37}) = \frac{1}{10}$ (так как нужное место одно, а всего мест 10)

$P(A_{73} | A_{37}) $ -- седьмое место занято, причем томом №3 -- тогда вероятность $ = \frac{1}{9}$

$P(A_{55} | A_{37}\cdot A_{73}) $ -- 3 и 7-е места заняты, 5 том единственный, нужное место одно -- тогда вероятность $ = \frac{1}{8} $

Тогда итоговая вероятность:

$$\frac{1}{10} \cdot \frac{1}{9} \cdot \frac{1}{8} = \frac{1}{720} $$

\quad

\quad

Конечно, полезно сделать отсылку и к КСТВ:

\quad

$N = 10!$ \qquad\qquad\qquad $N_A = 1 \cdot 7!$

\quad

Насчет $N_A$ : вариант расстановки конкретных томов один, но остается еще 7 свободных мест, которые надо перебрать. Тогда:

$$P(A) = \frac{N_A}{N} = \frac{1 \cdot 7!}{10!} = \frac{1}{8 \cdot 9 \cdot 10} = \frac{1}{720} $$

\section{Формула сложения}

Имеем два события $A$ и $B$. Пусть они совместные, то есть имеют общую часть $AB \not = \emptyset$.

Мы хотим найти $P(A + B) = P(A) + P(B) - P(AB)$ (явно видно из рисунка) для двух совместных событий.

\quad

Если мы данную формулу обобщим на три слагаемых, то получим:

$P(A + B + C) = P(A) + P(B) + P(C) - $

$\qquad\qquad\qquad\qquad- (P(AB) + P(AC) + P(BC)) + $

$\qquad\qquad\qquad\qquad+ P(ABC) $

Запись построена с учетом смены знаков и выделением трех этапов. То же самое в одну линию:

$$P(A + B + C) = P(A) + P(B) + P(C) - (P(AB) + P(AC) + P(BC)) + P(ABC) $$

\quad

Тот же вариант для 4 слагаемых:

$P(A + B + C + D) = P(A) + P(B) + P(C) + P(D) -$

$\qquad\qquad\qquad\qquad\qquad- (P(AB) + P(AC) + P(AD) + P(BC) + P(BD) + P(CD)) + $

$\qquad\qquad\qquad\qquad\qquad+ (P(ABC) + P(BCD) + P(ACD) + P(ABD)) -$

$\qquad\qquad\qquad\qquad\qquad- P(ABCD) $

\quad

И конечно же хотелось бы записать подобное в общем виде. Таким образом получаем формулу:

$$P\Biggl(\sum\limits_{i = 1}^n A_i\Biggr) = \sum\limits_{i = 1}^n P(A_i) - \sum\limits_{i < j} P(A_i \cdot A_j) + \sum\limits_{i < j < k} P(A_i \cdot A_j \cdot A_k) - \ldots + (-1)^{n - 1} P(A_1 \cdot \ldots \cdot A_n)$$

Или есть еще один вариант записи:

$$P\Biggl(\sum\limits_{i = 1}^n A_i\Biggr) = \sum\limits_{k = 1}^n (-1)^{k - 1} S_k,$$

где $$ S_k = \sum\limits_{i_1 < i_2 < \ldots < i_k} P(A_{i_1} \cdot A_{i_2} \cdot \ldots \cdot A_{i_k}) $$

\subsection {Замечание}
Сделаем еще одно важное замечание: из законов двойственности известно, что дополнением к сумме служит пересечение дополнений: $\overline{\cup_i A_i} = \cap_i A_i $ (и то же для множества переменных). То есть иногда можно вероятность суммы найти из произведения дополнений:

$$ P\Biggl(\sum\limits_i A_i\Biggr) = 1 - P\Biggl(\prod\limits_i \overline{A_i}\Biggr) $$

В частности для двух слагаемых:

$$P(A + B) = 1 - P(\overline{A} \cdot \overline{B}) $$

\subsection{Пример}

Некоторое n-томное издание наугад расставленно на полке. Нужно найти вероятность того, что хотя бы один том окажется на своем месте (номер места соответствует номеру тома).

\quad
Выглядит достаточно просто, можем даже построить все события:
$A_1 = \{$ 1-й том на своем месте $\}$

$A_2 = \{$ 2-й том на своем месте $\}$

...

$A_n = \{$ n-й том на своем месте. $\}$

\quad

А значит утверждение "хотя бы один том" можно было бы построить в виде суммы:

$B = \{$ хотя бы один том на своем месте $\}$

$B = A_1 + A_2 + \ldots + A_n$

$P(B) = P(A_1 + A_2 + \ldots + A_n) = \sum\limits_{k = 1}^n (-1)^{k - 1} \sum\limits_{i_1 < \ldots < i_n} P(A_{i_1} + A_{i_2} + \ldots + A_{i_n})$

\quad

Для того, чтобы с этой суммой разобраться, мы должны выписать один ее фрагмент: \newline$P(A_{i_1} + A_{i_2} + \ldots + A_{i_k})$ -- он означает, что некоторые тома $i_1, i_2, \ldots, i_k$  стоят на своих местах.

\begin{itemize}

\item Но мы знаем, что если расставим все тома всевозможными способы, то количество таких вариантов $\boldsymbol{= n!}$

\item Если эти $k$ томов стоят на своих местах, то вариант этого у нас всего \textbf{один} (одинаковых томов нет)

\item Тогда всеми возможными способами нам нужно расставить тома, не вошедшие в список, а их $\boldsymbol{(n - k)}!$
\end{itemize}

Таким образом, получаем:

$$P(A_{i_1} + A_{i_2} + \ldots + A_{i_k}) = \frac{1 \cdot (n - k)!}{n!}$$

Тогда следующий шаг: выяснить, а сколько слагаемых в этой сумме при фиксированном значении $k$. Причем мы можем одни $k$ томов выбрать, можем другие, но вероятность останется фиксированная (зависит от $k$). И это количество будет число сочетаний по k: $C_n^k$ (выбираем k возможных томов). В результате сумма несколько упростится:

$$ = \sum\limits_{k = 1}^n (-1)^{k - 1} \cdot C_n^k \frac{(n - k)!}{n!} = $$

$$ = \sum\limits_{k = 1}^n (-1)^{k - 1} \cdot \frac{n!}{(n - k)!k!} \cdot \frac{(n - k)!}{n!} = \sum\limits_{k = 1}^n (-1)^{k - 1} \cdot \frac{1}{k!} = $$

$$ = \frac{1}{1!} - \frac{1}{2!} + \frac{1}{3!} - \ldots + (-1)^{k-1} \frac{1}{n!} = $$

Если прибавить и отнять единицу:

$$ = 1 - \Biggl(1 - \frac{1}{1!} + \frac{1}{2!} - \frac{1}{3!} + \ldots - (-1)^{k-1} \frac{1}{n!}\Biggr)$$

Учитывая, что $1$ в скобках можно представить как $\frac{1}{0!}$ и что мы захотим хотя бы n >= 7, то запись может быть упрощена примерно следующим образом:

$$ \approx 1 - e^{-1} \approx 0,632$$

То есть запись в скобках -- это разложение экспоненты в ряд Тейлора.

\quad

Любопытно, что несмотря на то, что в условии ничего по сути не дано, ответ получился все равно числовой. Единственное ограничение -- количество томов, для такого упрощения оно должно быть достаточно большим. Однако, зато оно стабилизируется у некоторого числа.

\section{Независимость событий}

\textbf{Определение.} События $A$ и $B$ независимы (или статистически независимы) $\Leftrightarrow$ когда вероятность произведений равна произведению вероятностей:

$$P(AB) = P(A) \cdot P(B) $$

\textbf{Замечание.}  Событие $A$, $B$ и $C$ независимы $\Leftrightarrow$:


\begin{cases}
  $ P(ABC) = P(A)P(B)P(C)$\\
  $ P(AB) = P(A)P(B)$\\
  $ P(AC) = P(A)P(C)$\\
  $ P(BC) = P(B)P(C)$
\end{cases}


При этом можно сказать, что первое условие означает, что события независимы в совокупности, а оставшиеся три означают попарную независимость событий.

\subsection{Пример}

Бросают тетраэдр с гранями: Б(елый), С(иний), К(расный) и БСК.

Имеются 3 события: выпал Б(W), выпал С(B), выпал К(R). Вероятности:

\quad

$P(W) = P(B) = P(R) = \frac{2}{4} = \frac{1}{2}$ в силу симметрии

\quad

Если выпала трехцветная грань:

\begin{cases}

  $P(WB) = 1 / 4 = P(W)\cdot P(B) = \frac{1}{2} \cdot \frac{1}{2}$ & \text{(последнее \textbf{}из найденных ранее вероятностей)}\\ 
  $P(BR) = \ldots$ & \text{(то же самое)}\\
  $P(WR) = \ldots$ & \text{(аналогично)}
\end{cases}

\quad

$P(WBR) = \frac{1}{4} \not= P(W)\cdot P(B) \cdot P(R) = \frac{1}{8}$

Получается, что наши события незавиимы попарно, но зависимы в совокупности.

\end{document}
